# éƒ¨ç½²æŒ‡å—å®Œæ•´æ–‡æª”

> See `docs/deployment/CI_CD_NOTES.md` for GitHub Actions configuration.

## 1. éƒ¨ç½²æ¦‚è¿°

### 1.1 éƒ¨ç½²æ¶æ§‹

```
é–‹ç™¼ç’°å¢ƒ (Development)
    â†“
æ¸¬è©¦ç’°å¢ƒ (Staging)
    â†“
ç”Ÿç”¢ç’°å¢ƒ (Production)
```

### 1.2 éƒ¨ç½²ç­–ç•¥

- **è—ç¶ éƒ¨ç½²**ï¼šç”Ÿç”¢ç’°å¢ƒä½¿ç”¨è—ç¶ éƒ¨ç½²ç­–ç•¥
- **é‡‘çµ²é›€éƒ¨ç½²**ï¼šæ¼¸é€²å¼æµé‡åˆ‡æ›
- **è‡ªå‹•åŒ–éƒ¨ç½²**ï¼šCI/CD æµç¨‹è‡ªå‹•åŒ–
- **å¿«é€Ÿå›æ»¾**ï¼šå•é¡Œç™¼ç”Ÿæ™‚å¿«é€Ÿæ¢å¾©

## 2. ç’°å¢ƒé…ç½®

### 2.1 é–‹ç™¼ç’°å¢ƒé…ç½®

```bash
# ç’°å¢ƒè®Šæ•¸é…ç½®
NODE_ENV=development
GEMINI_API_KEY=your_dev_gemini_key
PINECONE_API_KEY=your_dev_pinecone_key
PINECONE_ENVIRONMENT=us-west1-gcp
REDIS_URL=redis://localhost:6379
VERCEL_TOKEN=your_dev_vercel_token
CLOUDFLARE_API_TOKEN=your_dev_cloudflare_token
```

### 2.2 æ¸¬è©¦ç’°å¢ƒé…ç½®

```bash
# ç’°å¢ƒè®Šæ•¸é…ç½®
NODE_ENV=staging
GEMINI_API_KEY=your_staging_gemini_key
PINECONE_API_KEY=your_staging_pinecone_key
PINECONE_ENVIRONMENT=us-west1-gcp
REDIS_URL=redis://staging-redis.example.com:6379
VERCEL_TOKEN=your_staging_vercel_token
CLOUDFLARE_API_TOKEN=your_staging_cloudflare_token
```

### 2.3 ç”Ÿç”¢ç’°å¢ƒé…ç½®

```bash
# ç’°å¢ƒè®Šæ•¸é…ç½®
NODE_ENV=production
GEMINI_API_KEY=your_prod_gemini_key
PINECONE_API_KEY=your_prod_pinecone_key
PINECONE_ENVIRONMENT=us-west1-gcp
REDIS_URL=redis://prod-redis.example.com:6379
VERCEL_TOKEN=your_prod_vercel_token
CLOUDFLARE_API_TOKEN=your_prod_cloudflare_token
```

## 3. éƒ¨ç½²æµç¨‹

### 3.1 é–‹ç™¼ç’°å¢ƒéƒ¨ç½²

```bash
# 1. æ§‹å»ºæ‡‰ç”¨
pnpm build

# 2. éƒ¨ç½²å‰ç«¯åˆ° Vercel
vercel --prod --token $VERCEL_TOKEN

# 3. éƒ¨ç½² API åˆ° Cloudflare
wrangler deploy --env development

# 4. éƒ¨ç½²æ•¸æ“šç®¡é“
cd apps/data-pipeline
python deploy.py --env development
```

### 3.2 æ¸¬è©¦ç’°å¢ƒéƒ¨ç½²

```bash
# 1. æ§‹å»ºæ‡‰ç”¨
pnpm build:staging

# 2. éƒ¨ç½²åˆ°æ¸¬è©¦ç’°å¢ƒ
vercel --prod --token $VERCEL_TOKEN_STAGING
wrangler deploy --env staging
```

### 3.3 ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²

```bash
# 1. æ§‹å»ºç”Ÿç”¢ç‰ˆæœ¬
pnpm build:production

# 2. éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ
vercel --prod --token $VERCEL_TOKEN_PROD
wrangler deploy --env production

# 3. é©—è­‰éƒ¨ç½²
pnpm test:production-validation
```

## 4. éƒ¨ç½²è…³æœ¬

### 4.1 è‡ªå‹•åŒ–éƒ¨ç½²è…³æœ¬

```bash
#!/bin/bash
# deploy.sh

set -e

ENVIRONMENT=$1
VERSION=$2

if [ -z "$ENVIRONMENT" ] || [ -z "$VERSION" ]; then
    echo "Usage: ./deploy.sh <environment> <version>"
    echo "Example: ./deploy.sh production v1.2.3"
    exit 1
fi

echo "ğŸš€ Starting deployment to $ENVIRONMENT (version: $VERSION)"

# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
check_environment_variables() {
    local env=$1
    case $env in
        "development")
            required_vars=("DEV_GEMINI_API_KEY" "DEV_PINECONE_API_KEY")
            ;;
        "staging")
            required_vars=("STAGING_GEMINI_API_KEY" "STAGING_PINECONE_API_KEY")
            ;;
        "production")
            required_vars=("PROD_GEMINI_API_KEY" "PROD_PINECONE_API_KEY")
            ;;
        *)
            echo "âŒ Unknown environment: $env"
            exit 1
            ;;
    esac

    for var in "${required_vars[@]}"; do
        if [ -z "${!var}" ]; then
            echo "âŒ Missing environment variable: $var"
            exit 1
        fi
    done
}

# æ§‹å»ºæ‡‰ç”¨
build_application() {
    echo "ğŸ”¨ Building application..."
    pnpm install
    pnpm build:$ENVIRONMENT

    if [ $? -eq 0 ]; then
        echo "âœ… Build completed successfully"
    else
        echo "âŒ Build failed"
        exit 1
    fi
}

# éƒ¨ç½²å‰ç«¯
deploy_frontend() {
    echo "ğŸŒ Deploying frontend..."
    case $ENVIRONMENT in
        "development")
            vercel --prod --token $DEV_VERCEL_TOKEN
            ;;
        "staging")
            vercel --prod --token $STAGING_VERCEL_TOKEN
            ;;
        "production")
            vercel --prod --token $PROD_VERCEL_TOKEN
            ;;
    esac
}

# éƒ¨ç½² API
deploy_api() {
    echo "ğŸ”Œ Deploying API..."
    case $ENVIRONMENT in
        "development")
            wrangler deploy --env development
            ;;
        "staging")
            wrangler deploy --env staging
            ;;
        "production")
            wrangler deploy --env production
            ;;
    esac
}

# éƒ¨ç½²æ•¸æ“šç®¡é“
deploy_data_pipeline() {
    echo "ğŸ“Š Deploying data pipeline..."
    cd apps/data-pipeline

    case $ENVIRONMENT in
        "development")
            python deploy.py --env development
            ;;
        "staging")
            python deploy.py --env staging
            ;;
        "production")
            python deploy.py --env production
            ;;
    esac

    cd ../..
}

# é©—è­‰éƒ¨ç½²
validate_deployment() {
    echo "âœ… Validating deployment..."

    # ç­‰å¾…æœå‹™å•Ÿå‹•
    sleep 30

    # å¥åº·æª¢æŸ¥
    case $ENVIRONMENT in
        "development")
            curl -f $DEV_FRONTEND_URL/api/health
            curl -f $DEV_API_URL/health
            ;;
        "staging")
            curl -f $STAGING_FRONTEND_URL/api/health
            curl -f $STAGING_API_URL/health
            ;;
        "production")
            curl -f $PROD_FRONTEND_URL/api/health
            curl -f $PROD_API_URL/health
            ;;
    esac

    echo "âœ… Health checks passed"
}

# ä¸»éƒ¨ç½²æµç¨‹
main() {
    echo "ğŸš€ Starting deployment process..."

    check_environment_variables $ENVIRONMENT
    build_application
    deploy_frontend
    deploy_api
    deploy_data_pipeline
    validate_deployment

    echo "ğŸ‰ Deployment to $ENVIRONMENT completed successfully!"
    echo "ğŸ“… Deployment time: $(date)"
    echo "ğŸ·ï¸  Version: $VERSION"
}

main
```

### 4.2 å›æ»¾è…³æœ¬

```bash
#!/bin/bash
# rollback.sh

set -e

ENVIRONMENT=$1
VERSION=$2

if [ -z "$ENVIRONMENT" ] || [ -z "$VERSION" ]; then
    echo "Usage: ./rollback.sh <environment> <version>"
    echo "Example: ./rollback.sh production v1.2.2"
    exit 1
fi

echo "ğŸ”„ Starting rollback to $VERSION on $ENVIRONMENT"

rollback_frontend() {
    echo "ğŸŒ Rolling back frontend..."
    case $ENVIRONMENT in
        "production")
            vercel rollback $VERSION --token $PROD_VERCEL_TOKEN
            ;;
        *)
            echo "âš ï¸  Rollback not supported for $ENVIRONMENT"
            ;;
    esac
}

rollback_api() {
    echo "ğŸ”Œ Rolling back API..."
    case $ENVIRONMENT in
        "production")
            wrangler rollback --env production --version $VERSION
            ;;
        *)
            echo "âš ï¸  Rollback not supported for $ENVIRONMENT"
            ;;
    esac
}

rollback_data_pipeline() {
    echo "ğŸ“Š Rolling back data pipeline..."
    case $ENVIRONMENT in
        "production")
            cd apps/data-pipeline
            python rollback.py --env production --version $VERSION
            cd ../..
            ;;
        *)
            echo "âš ï¸  Rollback not supported for $ENVIRONMENT"
            ;;
    esac
}

main() {
    echo "ğŸ”„ Starting rollback process..."

    rollback_frontend
    rollback_api
    rollback_data_pipeline

    echo "âœ… Rollback to $VERSION completed successfully!"
    echo "ğŸ“… Rollback time: $(date)"
}

main
```

## 5. ç›£æ§å’Œç¶­è­·

### 5.1 å¥åº·æª¢æŸ¥ç«¯é»

```typescript
// å¥åº·æª¢æŸ¥å¯¦ç¾
app.get('/health', async (req, res) => {
  try {
    // æª¢æŸ¥æ•¸æ“šåº«é€£æ¥
    const dbStatus = await checkDatabaseConnection();

    // æª¢æŸ¥å¤–éƒ¨æœå‹™
    const geminiStatus = await checkGeminiService();
    const pineconeStatus = await checkPineconeService();

    // æª¢æŸ¥ç³»çµ±è³‡æº
    const systemStatus = await checkSystemResources();

    const healthStatus = {
      status: 'healthy',
      timestamp: new Date().toISOString(),
      version: process.env.APP_VERSION || 'unknown',
      services: {
        database: dbStatus,
        gemini: geminiStatus,
        pinecone: pineconeStatus,
        system: systemStatus,
      },
      uptime: process.uptime(),
    };

    const isHealthy = Object.values(healthStatus.services).every(
      service => service.status === 'healthy'
    );

    if (isHealthy) {
      res.status(200).json(healthStatus);
    } else {
      res.status(503).json({
        ...healthStatus,
        status: 'unhealthy',
      });
    }
  } catch (error) {
    res.status(503).json({
      status: 'error',
      timestamp: new Date().toISOString(),
      error: error.message,
    });
  }
});

// è©³ç´°å¥åº·æª¢æŸ¥
app.get('/health/detailed', async (req, res) => {
  const detailedHealth = await getDetailedHealthStatus();
  res.json(detailedHealth);
});
```

### 5.2 æ€§èƒ½ç›£æ§

```typescript
// æ€§èƒ½ç›£æ§ä¸­é–“ä»¶
import { performance } from 'perf_hooks';

export const performanceMonitor = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  const start = performance.now();

  // ç›£è½éŸ¿æ‡‰å®Œæˆ
  res.on('finish', () => {
    const duration = performance.now() - start;

    // è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
    recordPerformanceMetric({
      path: req.path,
      method: req.method,
      statusCode: res.statusCode,
      duration,
      timestamp: new Date(),
      userAgent: req.get('User-Agent'),
      ip: req.ip,
    });

    // æª¢æŸ¥æ€§èƒ½é–¾å€¼
    if (duration > 1000) {
      // è¶…é1ç§’
      console.warn(
        `Slow request: ${req.method} ${req.path} took ${duration.toFixed(2)}ms`
      );
    }
  });

  next();
};

// æ€§èƒ½æŒ‡æ¨™è¨˜éŒ„
interface PerformanceMetric {
  path: string;
  method: string;
  statusCode: number;
  duration: number;
  timestamp: Date;
  userAgent?: string;
  ip?: string;
}

const recordPerformanceMetric = (metric: PerformanceMetric) => {
  // å­˜å„²åˆ°ç›£æ§ç³»çµ±
  // é€™è£¡å¯ä»¥é›†æˆ Prometheusã€DataDog ç­‰ç›£æ§å·¥å…·
  console.log('Performance metric:', metric);
};
```

### 5.3 æ—¥èªŒç®¡ç†

```typescript
// æ—¥èªŒé…ç½®
import winston from 'winston';

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'concept-stock-screener' },
  transports: [
    // éŒ¯èª¤æ—¥èªŒ
    new winston.transports.File({
      filename: 'logs/error.log',
      level: 'error',
      maxsize: 5242880, // 5MB
      maxFiles: 5,
    }),

    // æ‰€æœ‰æ—¥èªŒ
    new winston.transports.File({
      filename: 'logs/combined.log',
      maxsize: 5242880, // 5MB
      maxFiles: 5,
    }),
  ],
});

// ç”Ÿç”¢ç’°å¢ƒæ·»åŠ æ§åˆ¶å°è¼¸å‡º
if (process.env.NODE_ENV !== 'production') {
  logger.add(
    new winston.transports.Console({
      format: winston.format.simple(),
    })
  );
}

export default logger;
```

## 6. å®‰å…¨é…ç½®

### 6.1 å®‰å…¨é ­éƒ¨é…ç½®

```typescript
// å®‰å…¨ä¸­é–“ä»¶
import helmet from 'helmet';

// é…ç½®å®‰å…¨é ­éƒ¨
app.use(
  helmet({
    contentSecurityPolicy: {
      directives: {
        defaultSrc: ["'self'"],
        styleSrc: ["'self'", "'unsafe-inline'"],
        scriptSrc: ["'self'"],
        imgSrc: ["'self'", 'data:', 'https:'],
        connectSrc: [
          "'self'",
          'https://api.gemini.com',
          'https://api.pinecone.io',
        ],
        frameSrc: ["'none'"],
        objectSrc: ["'none'"],
      },
    },
    hsts: {
      maxAge: 31536000,
      includeSubDomains: true,
      preload: true,
    },
    noSniff: true,
    referrerPolicy: { policy: 'strict-origin-when-cross-origin' },
  })
);

// CORS é…ç½®
app.use(
  cors({
    origin: process.env.ALLOWED_ORIGINS?.split(',') || [
      'http://localhost:3000',
    ],
    credentials: true,
    methods: ['GET', 'POST', 'PUT', 'DELETE'],
    allowedHeaders: ['Content-Type', 'Authorization'],
  })
);
```

### 6.2 ç’°å¢ƒè®Šæ•¸å®‰å…¨

```bash
# .env.example (ä¸è¦åŒ…å«å¯¦éš›å¯†é‘°)
NODE_ENV=development
GEMINI_API_KEY=your_gemini_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment
REDIS_URL=redis://localhost:6379
VERCEL_TOKEN=your_vercel_token_here
CLOUDFLARE_API_TOKEN=your_cloudflare_token_here

# å®‰å…¨é…ç½®
JWT_SECRET=your_jwt_secret_here
SESSION_SECRET=your_session_secret_here
ENCRYPTION_KEY=your_encryption_key_here

# é™åˆ¶é…ç½®
RATE_LIMIT_WINDOW=900000
RATE_LIMIT_MAX_REQUESTS=100
MAX_FILE_SIZE=10485760
```

## 7. å‚™ä»½å’Œæ¢å¾©

### 7.1 æ•¸æ“šå‚™ä»½ç­–ç•¥

```bash
#!/bin/bash
# backup.sh

set -e

BACKUP_DIR="/backups/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

echo "ğŸ”„ Starting backup process..."

# å‚™ä»½å‘é‡æ•¸æ“šåº«
echo "ğŸ“Š Backing up vector database..."
wrangler kv:bulk export --env production > $BACKUP_DIR/vectors.json

# å‚™ä»½ Redis æ•¸æ“š
echo "ğŸ”´ Backing up Redis data..."
redis-cli --rdb $BACKUP_DIR/redis.rdb

# å‚™ä»½é…ç½®æ–‡ä»¶
echo "âš™ï¸  Backing up configuration files..."
cp -r config/ $BACKUP_DIR/
cp .env.production $BACKUP_DIR/

# å‚™ä»½æ—¥èªŒæ–‡ä»¶
echo "ğŸ“ Backing up log files..."
cp -r logs/ $BACKUP_DIR/

# å£“ç¸®å‚™ä»½
echo "ğŸ—œï¸  Compressing backup..."
tar -czf $BACKUP_DIR.tar.gz -C $BACKUP_DIR .

# æ¸…ç†è‡¨æ™‚æ–‡ä»¶
rm -rf $BACKUP_DIR

echo "âœ… Backup completed: $BACKUP_DIR.tar.gz"

# ä¸Šå‚³åˆ°é›²å­˜å„²
echo "â˜ï¸  Uploading to cloud storage..."
aws s3 cp $BACKUP_DIR.tar.gz s3://backup-bucket/concept-stock-screener/

echo "ğŸ‰ Backup process completed successfully!"
```

### 7.2 ç½é›£æ¢å¾©æµç¨‹

```bash
#!/bin/bash
# disaster-recovery.sh

set -e

BACKUP_FILE=$1
ENVIRONMENT=$2

if [ -z "$BACKUP_FILE" ] || [ -z "$ENVIRONMENT" ]; then
    echo "Usage: ./disaster-recovery.sh <backup_file> <environment>"
    echo "Example: ./disaster-recovery.sh backup-20240115.tar.gz production"
    exit 1
fi

echo "ğŸš¨ Starting disaster recovery process..."
echo "ğŸ“¦ Backup file: $BACKUP_FILE"
echo "ğŸŒ Environment: $ENVIRONMENT"

# åœæ­¢æœå‹™
stop_services() {
    echo "ğŸ›‘ Stopping services..."
    # å¯¦ç¾åœæ­¢æœå‹™çš„é‚è¼¯
    echo "âœ… Services stopped"
}

# æ¢å¾©æ•¸æ“š
restore_data() {
    echo "ğŸ”„ Restoring data from backup..."

    # è§£å£“å‚™ä»½æ–‡ä»¶
    tar -xzf $BACKUP_FILE

    # æ¢å¾©å‘é‡æ•¸æ“šåº«
    echo "ğŸ“Š Restoring vector database..."
    wrangler kv:bulk import --env $ENVIRONMENT vectors.json

    # æ¢å¾© Redis æ•¸æ“š
    echo "ğŸ”´ Restoring Redis data..."
    redis-cli --rdb redis.rdb

    # æ¢å¾©é…ç½®æ–‡ä»¶
    echo "âš™ï¸  Restoring configuration files..."
    cp -r config/* ./
    cp .env.$ENVIRONMENT .env

    echo "âœ… Data restoration completed"
}

# å•Ÿå‹•æœå‹™
start_services() {
    echo "ğŸš€ Starting services..."
    # å¯¦ç¾å•Ÿå‹•æœå‹™çš„é‚è¼¯
    echo "âœ… Services started"
}

# é©—è­‰æ¢å¾©
verify_recovery() {
    echo "âœ… Verifying recovery..."

    # ç­‰å¾…æœå‹™å•Ÿå‹•
    sleep 30

    # å¥åº·æª¢æŸ¥
    curl -f http://localhost:3000/health

    echo "âœ… Recovery verification completed"
}

# ä¸»æ¢å¾©æµç¨‹
main() {
    echo "ğŸš¨ Starting disaster recovery..."

    stop_services
    restore_data
    start_services
    verify_recovery

    echo "ğŸ‰ Disaster recovery completed successfully!"
    echo "ğŸ“… Recovery time: $(date)"
}

main
```

## 8. éƒ¨ç½²æª¢æŸ¥æ¸…å–®

### 8.1 éƒ¨ç½²å‰æª¢æŸ¥

- [ ] ä»£ç¢¼å¯©æŸ¥å®Œæˆ
- [ ] æ¸¬è©¦é€šé
- [ ] ç’°å¢ƒè®Šæ•¸é…ç½®æ­£ç¢º
- [ ] ä¾è³´åŒ…ç‰ˆæœ¬ç¢ºèª
- [ ] æ•¸æ“šåº«é·ç§»è…³æœ¬æº–å‚™
- [ ] å›æ»¾è¨ˆåŠƒæº–å‚™

### 8.2 éƒ¨ç½²ä¸­æª¢æŸ¥

- [ ] æ§‹å»ºæˆåŠŸ
- [ ] éƒ¨ç½²åˆ°ç›®æ¨™ç’°å¢ƒ
- [ ] å¥åº·æª¢æŸ¥é€šé
- [ ] åŠŸèƒ½æ¸¬è©¦é€šé
- [ ] æ€§èƒ½æ¸¬è©¦é€šé

### 8.3 éƒ¨ç½²å¾Œæª¢æŸ¥

- [ ] ç›£æ§æŒ‡æ¨™æ­£å¸¸
- [ ] éŒ¯èª¤æ—¥èªŒæª¢æŸ¥
- [ ] ç”¨æˆ¶åé¥‹æ”¶é›†
- [ ] æ€§èƒ½åŸºæº–æ¯”è¼ƒ
- [ ] æ–‡æª”æ›´æ–°

## 9. å¸¸è¦‹å•é¡Œå’Œæ•…éšœæ’é™¤

### 9.1 éƒ¨ç½²å¤±æ•—å•é¡Œ

```bash
# æª¢æŸ¥éƒ¨ç½²æ—¥èªŒ
vercel logs --token $VERCEL_TOKEN
wrangler tail --env production

# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
echo $GEMINI_API_KEY
echo $PINECONE_API_KEY

# æª¢æŸ¥æœå‹™ç‹€æ…‹
curl -f $FRONTEND_URL/api/health
curl -f $API_URL/health
```

### 9.2 æ€§èƒ½å•é¡Œ

```bash
# æª¢æŸ¥ç³»çµ±è³‡æº
htop
df -h
free -h

# æª¢æŸ¥ç¶²çµ¡å»¶é²
ping api.gemini.com
ping api.pinecone.io

# æª¢æŸ¥æ•¸æ“šåº«æ€§èƒ½
redis-cli info memory
redis-cli info stats
```

### 9.3 å®‰å…¨å•é¡Œ

```bash
# æª¢æŸ¥å®‰å…¨æƒæ
npm audit
npm audit fix

# æª¢æŸ¥ä¾è³´æ¼æ´
snyk test

# æª¢æŸ¥ SSL è­‰æ›¸
openssl s_client -connect your-domain.com:443
```

## 10. æˆåŠŸæ¨™æº–å’Œ KPI

### 10.1 éƒ¨ç½²æˆåŠŸç‡

- **ç›®æ¨™**ï¼šâ‰¥ 99.5%
- **æ¸¬é‡**ï¼šæˆåŠŸéƒ¨ç½²æ¬¡æ•¸ / ç¸½éƒ¨ç½²æ¬¡æ•¸

### 10.2 éƒ¨ç½²æ™‚é–“

- **é–‹ç™¼ç’°å¢ƒ**ï¼šâ‰¤ 5 åˆ†é˜
- **æ¸¬è©¦ç’°å¢ƒ**ï¼šâ‰¤ 10 åˆ†é˜
- **ç”Ÿç”¢ç’°å¢ƒ**ï¼šâ‰¤ 20 åˆ†é˜

### 10.3 ç³»çµ±å¯ç”¨æ€§

- **ç›®æ¨™**ï¼šâ‰¥ 99.9%
- **æ¸¬é‡**ï¼šç³»çµ±é‹è¡Œæ™‚é–“ / ç¸½æ™‚é–“

### 10.4 æ¢å¾©æ™‚é–“

- **ç›®æ¨™**ï¼šâ‰¤ 15 åˆ†é˜
- **æ¸¬é‡**ï¼šå¾æ•…éšœåˆ°æ¢å¾©çš„æ™‚é–“

## 11. å¾ŒçºŒæ­¥é©Ÿ

### 11.1 ç«‹å³åŸ·è¡Œ

1. é…ç½®ç’°å¢ƒè®Šæ•¸
2. è¨­ç½®ç›£æ§ç³»çµ±
3. å»ºç«‹å‚™ä»½æµç¨‹

### 11.2 çŸ­æœŸç›®æ¨™ (1-2 é€±)

1. å®Œæˆè‡ªå‹•åŒ–éƒ¨ç½²
2. å»ºç«‹ç›£æ§å„€è¡¨æ¿
3. å¯¦ç¾è‡ªå‹•åŒ–å‚™ä»½

### 11.3 ä¸­æœŸç›®æ¨™ (3-4 é€±)

1. å„ªåŒ–éƒ¨ç½²æµç¨‹
2. å¯¦ç¾è—ç¶ éƒ¨ç½²
3. å»ºç«‹ç½é›£æ¢å¾©è¨ˆåŠƒ

### 11.4 é•·æœŸç›®æ¨™ (6-8 é€±)

1. å¯¦ç¾é›¶åœæ©Ÿéƒ¨ç½²
2. å»ºç«‹å®Œæ•´çš„ç›£æ§ç”Ÿæ…‹
3. è‡ªå‹•åŒ–æ•…éšœæ¢å¾©
